{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a765a87d",
   "metadata": {},
   "source": [
    "# file contains \n",
    "- f1_score\n",
    "- all 3 distances\n",
    "- tuning_without_scaling\n",
    "- tuning_with_scaling\n",
    "- MinMaxScaler\n",
    "- NormalizationScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac836a76",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'test_utils_full'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fz/zn5r8vq12nv5p23dtlr15sk40000gn/T/ipykernel_67520/1697616990.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# read this https://github.com/ipython/ipynb for importing notebooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mipynb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_knn_full\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/development/csci_567_machine_learning/1-knn/my_code/test_files/test_knn_full.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;34m\"#             print(\\\"count_zeros : \\\", count_zeros)\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0;34m\"#             compare\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;34m\"            if  count_ones >  count_zeros : \\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;34m\"                most_labels.append(1)\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'test_utils_full'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# read this https://github.com/ipython/ipynb for importing notebooks\n",
    "from ipynb.fs.full.test_knn_full import KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f1ca2",
   "metadata": {},
   "source": [
    "# Functions\n",
    "1. f1_score\n",
    "    - Information on F1 score - https://en.wikipedia.org/wiki/F1_score\n",
    "    - :param real_labels: List[int]\n",
    "    - :param predicted_labels: List[int]\n",
    "    - :return: float\n",
    "\n",
    "2. minkowski_distance\n",
    "    - Minkowski distance is the generalized version of Euclidean Distance\n",
    "    - It is also know as L-p norm (where p>=1) that you have studied in class\n",
    "    - For our assignment we need to take p=3\n",
    "    - Information on Minkowski distance - https://en.wikipedia.org/wiki/Minkowski_distance\n",
    "    - :param point1: List[float]\n",
    "    - :param point2: List[float]\n",
    "    - :return: float\n",
    " \n",
    "3. euclidean_distance\n",
    "    - :param point1: List[float]\n",
    "    - :param point2: List[float]\n",
    "    - :return: float\n",
    "    \n",
    "4. cosine_similarity_distance\n",
    "   - :param point1: List[float]\n",
    "   - :param point2: List[float]\n",
    "   - :return: float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c56ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(real_labels, predicted_labels):\n",
    "# assert keyword tests if a condition is true\n",
    "    assert len(real_labels) == len(predicted_labels)\n",
    "#     raise NotImplementedError\n",
    "#     1s : positive\n",
    "#     0s: negative\n",
    "\n",
    "    total_labels = len(real_labels) + len(predicted_labels)\n",
    "    \n",
    "#     get t_p : collect all the 1s in t_p\n",
    "#     loop either r_l or p_l; same lenght so doesn't matter\n",
    "    true_positive = 0\n",
    "    for i in range(len(real_labels)) :\n",
    "#         print(i, \"real_labels : predicted_labels ==>\", real_labels[i], predicted_labels[i])\n",
    "#         ask : at this position, is there a 1; \n",
    "        if (real_labels[i] == 1) and (predicted_labels[i] == 1) :\n",
    "            true_positive += 1\n",
    "    \n",
    "#     get t_p_p :         \n",
    "    total_predicted_positive = 0\n",
    "    for i in range(len(real_labels)) :\n",
    "        if predicted_labels[i] == 1 :\n",
    "            total_predicted_positive += 1 \n",
    "    \n",
    "#     get f_n : evaluate both real & predicted\n",
    "    false_negative = 0\n",
    "    for i in range(len(real_labels)) :\n",
    "#         print(i, \"real_labels : predicted_labels ==>\", real_labels[i], predicted_labels[i])\n",
    "        if (real_labels[i] == 1) and (predicted_labels[i] == 0) :\n",
    "            false_negative += 1\n",
    "#     print(\"false_negative : \", false_negative)\n",
    "    \n",
    "    try:\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "    except ZeroDivisionError:\n",
    "        recall = 0\n",
    "    try:\n",
    "        precision = true_positive / total_predicted_positive\n",
    "    except ZeroDivisionError:\n",
    "        precision = 0\n",
    "    \n",
    "    try:\n",
    "        f1_score = ((precision * recall) / (precision + recall)) * 2\n",
    "    except ZeroDivisionError:\n",
    "        f1_score = 0\n",
    "    \n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70db995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distances:\n",
    "    @staticmethod\n",
    "    def minkowski_distance(point1, point2):\n",
    "    #         raise NotImplementedError\n",
    "    #         difference between x and x_prime\n",
    "        x_minus_x_prime = np.subtract(point1, point2)\n",
    "\n",
    "        absolute_of_differece = np.absolute(x_minus_x_prime)\n",
    "\n",
    "            # doc : https://numpy.org/doc/stable/reference/generated/numpy.power.html?highlight=cube\n",
    "        cubed_diff = pow(absolute_of_differece, 3)\n",
    "\n",
    "    #         cube diff\n",
    "        sum_of_cubed_diff = np.sum(cubed_diff)\n",
    "\n",
    "    #         cubed root the sum\n",
    "        cubed_root_of_sum = np.cbrt(sum_of_cubed_diff)\n",
    "\n",
    "        return cubed_root_of_sum\n",
    "    \n",
    "    @staticmethod\n",
    "    def euclidean_distance(point1, point2):\n",
    "    #         difference between x and x_prime\n",
    "        x_minus_x_prime = np.subtract(point1, point2)\n",
    "\n",
    "    #         square difference\n",
    "        squ_diff = pow(x_minus_x_prime, 2)\n",
    "\n",
    "    #         sum diff\n",
    "        sum_of_squ_diff = np.sum(squ_diff)\n",
    "\n",
    "    #         square root the sum\n",
    "        squ_root_of_sum = np.sqrt(sum_of_squ_diff)\n",
    "\n",
    "        return squ_root_of_sum\n",
    "    \n",
    "    @staticmethod\n",
    "    def cosine_similarity_distance(point1, point2):\n",
    "    #     print(point1)\n",
    "        addition_for_p1 = 0\n",
    "\n",
    "        square_points = np.square(point1) \n",
    "        addition_for_p1 = np.sum(square_points)\n",
    "    #     print(\"addition_for_p1 : \", addition_for_p1)\n",
    "\n",
    "        square_points2 = np.square(point2) \n",
    "        addition_for_p2 = np.sum(square_points2)\n",
    "    #     print(\"addition_for_p2 : \", addition_for_p2)\n",
    "\n",
    "\n",
    "        numerator = np.sum(np.multiply(point1, point2))\n",
    "        denom = np.multiply(np.sqrt(addition_for_p1), np.sqrt(addition_for_p2))\n",
    "#         print(\"numerator = \", numerator, \"& denom = \", denom)\n",
    "        if denom == 0 :\n",
    "            return1_minus = 0\n",
    "        else : \n",
    "            return1_minus = 1 - (numerator / denom)\n",
    "\n",
    "        if addition_for_p1 == 0 or addition_for_p2 == 0 :\n",
    "            return  1\n",
    "        else :\n",
    "            return return1_minus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34242145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o = 1\n",
    "# n = 0\n",
    "# d = 0\n",
    "# if d == 0 :\n",
    "#     r = 0\n",
    "# else :\n",
    "#     r = o - n / d\n",
    "# r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdeac35",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937bb277",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_labels = [1, 1, 1, 1, 1]\n",
    "p_labels = [0, 1, 0, 0, 0]\n",
    "\n",
    "point1 = [1.0, 2.0]\n",
    "point2 = [2.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebf5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if each label in r matches p, respectfully, then return 1\n",
    "f1_score(r_labels, p_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5558ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't need - just being lazy instead of changing values in r_labels & p_labels, I just created another set \n",
    "# if every label in r differs p, respectfully, then return 0\n",
    "\n",
    "label_train = np.array([0, 0, 0, 0, 0, 0])\n",
    "label_val = np.array([0, 1, 0, 0, 1, 1])\n",
    "\n",
    "f1_score(label_train, label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538eeaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b85a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.minkowski_distance(point1, point2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89519aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.euclidean_distance(point1, point2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef68321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.cosine_similarity_distance(point1, point2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cdc2b8",
   "metadata": {},
   "source": [
    "# Class\n",
    "1. HyperparameterTuner\n",
    "\n",
    "## Functions\n",
    "\n",
    "1. tuning_without_scaling : \n",
    "    \n",
    "        In this part, you need to try different distance functions you implemented in part 1.1 and different values of k (among 1, 3, 5, ... , 29), and find the best model with the highest f1-score on the given validation set.\n",
    "            ==> validation set : what to test funcs & k on \n",
    "            ==> try all 3 dist funcs\n",
    "            ==> k values : odd #s from 1 - 30 step 2; call function to get k values (knn.py file) here, write a func to look inside of my knn.py & call the func w/ k values\n",
    "            ==> model w/ highest f1 score : from this class, call my f1_score func\n",
    "\n",
    "        :param distance_funcs: dictionary of distance functions (key is the function name, value is the function) you need to try to calculate the distance. Make sure you loop over all distance functions for each k value.\n",
    "            ==> for k in len(self.k), \n",
    "            ==> :param dist_funcs : {'key' : value, 'key' : value, 'key' : value}\n",
    "                ==> dist_funcs = {\n",
    "                    'minkowski_distance' : minkowski_distance(point1, point2), \n",
    "                    'euclidean_distance' : euclidean_distance(point1, point2),\n",
    "                    'cosine_similarity_distance' : cosine_similarity_distance(point1, point2)\n",
    "                    }\n",
    "                ==> which dist_func returns the smallest value for this k\n",
    "            ==> return best dist_func\n",
    "            ==> starting at 1, loop through k up to 29 & get the best dist_func for each k along the w/ the best k & best f1_score\n",
    "            ==> once we get this, it will be our best model\n",
    "            \n",
    "        :param x_train: List[List[int]] training data set to train your KNN model\n",
    "            ==> features to train\n",
    "        :param y_train: List[int] training labels to train your KNN model\n",
    "            ==> labels to train [list of 0s or 1s]\n",
    "        :param x_val:  List[List[int]] validation data\n",
    "            ==> features for validation set to find f1 score & best model\n",
    "        :param y_val: List[int] validation labels\n",
    "            ==> labels for validation set to find f1 score & best model\n",
    "        \n",
    "\n",
    "        Find the best k, distance_function (its name), and model (an instance of KNN) and assign them to self.best_k,\n",
    "        self.best_distance_function, and self.best_model respectively.\n",
    "            ==> self.best_k = best k value\n",
    "            ==> self.best_distance_function = 1 of the 3 dist funcs\n",
    "            ==> self.best_model = small knn is the object of the capital KNN class [see testKNN] so return the best model by calling the KKN class\n",
    "                store max f1 score\n",
    "\n",
    "        NOTE: self.best_scaler will be None.\n",
    "\n",
    "        NOTE: When there is a tie, choose the model based on the following priorities:\n",
    "        First check the distance function:  euclidean > Minkowski > cosine_dist\n",
    "\t\t(this will also be the insertion order in \"distance_funcs\", to make things easier).\n",
    "        For the same distance function, further break tie by prioritizing a smaller k.\n",
    "2. tuning_with_scaling : \n",
    "\n",
    "        This part is the same as \"tuning_without_scaling\", except that you also need to try two different scalers implemented in Part 1.3. More specifically, before passing the training and validation data to KNN model, apply the scalers in scaling_classes to both of them.\n",
    "\n",
    "        :param distance_funcs: dictionary of distance functions (key is the function name, value is the function) you need to try to calculate the distance. Make sure you loop over all distance functions for each k value.\n",
    "        :param scaling_classes: dictionary of scalers (key is the scaler name, value is the scaler class) you need to try to normalize your data\n",
    "        :param x_train: List[List[int]] training data set to train your KNN model\n",
    "        :param y_train: List[int] train labels to train your KNN model\n",
    "        :param x_val: List[List[int]] validation data\n",
    "        :param y_val: List[int] validation labels\n",
    "\n",
    "        Find the best k, distance_function (its name), scaler (its name), and model (an instance of KNN), and assign them to self.best_k, self.best_distance_function, best_scaler, and self.best_model respectively.\n",
    "\n",
    "        NOTE: When there is a tie, choose the model based on the following priorities:\n",
    "        First check scaler, prioritizing \"min_max_scale\" over \"normalize\" (which will also be the insertion order of scaling_classes). Then follow the same rule as in \"tuning_without_scaling\".\n",
    "            ==> ex. if multiple best ks, which to choose\n",
    "            ==> break tie by \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c5f9f7",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "class HyperparameterTuner:\n",
    "    def __init__(self):\n",
    "        self.best_k = None # inner\n",
    "        self.best_distance_function = None # outer\n",
    "        self.best_scaler = None\n",
    "        self.best_model = None # pass d_f here; \n",
    "\n",
    "    # TODO: find parameters with the best f1 score on validation dataset\n",
    "    def tuning_without_scaling(self, distance_funcs, x_train, y_train, x_val, y_val):\n",
    "#         raise NotImplementedError\n",
    "        max_f1 = -1\n",
    "#         if there are less than 30 points, can't have 30 neighbors\n",
    "        bound = min(30, len(x_train))\n",
    "        for name, dist_val in distance_funcs.items() :\n",
    "#             print(name, \" : \", dist_val)\n",
    "        \n",
    "            for k_nums in range(1, bound, 2) :\n",
    "#                 print(\"k : \", k)\n",
    "\n",
    "                knn_m = KNN(k_nums, dist_val)\n",
    "#                 print(\"knn_m : \", knn_m)\n",
    "\n",
    "                knn_m.train(x_train, y_train)\n",
    "#                 print(\"knn.train : \",  train)\n",
    "#                 get f1 score & store them\n",
    "#                 p = predict\n",
    "                p = knn_m.predict(x_val)\n",
    "                \n",
    "#                 get the max f1\n",
    "                f1 = f1_score(y_val, p)\n",
    "\n",
    "                if f1 > max_f1 :\n",
    "#                     new max\n",
    "                    max_f1 = f1\n",
    "#                     print(\"max_f1 : \", max_f1)   \n",
    "\n",
    "                    self.best_k = k_nums\n",
    "#                     print(\"self.best_k : \", self.best_k)\n",
    "                \n",
    "#                     if self.best_k == self.best_k :\n",
    "#                         self.best_distance_function = name\n",
    "#                     else : \n",
    "                    self.best_distance_function = name\n",
    "#                     print(\"self.best_distance_function : \", self.best_distance_function)\n",
    "\n",
    "                    self.best_model = knn_m\n",
    "#                     print(\"self.best_model : \", self.best_model)\n",
    "#                 print(name, k_nums, f1, dist_val)\n",
    "#                 print(\"k_nums = \", k_nums, \"w/ f1 of : \", f1, \"& dist_val being : \", dist_val)\n",
    "    # TODO: find parameters with the best f1 score on validation dataset, with normalized data\n",
    "    def tuning_with_scaling(self, distance_funcs, scaling_classes, x_train, y_train, x_val, y_val):\n",
    "        max_f1 = -1\n",
    "#         if there are less than 30 points, can't have 30 neighbors\n",
    "        bound = min(30, len(x_train))\n",
    "                    \n",
    "        for name, dist_val in distance_funcs.items() :\n",
    "#             print(name, \" : \", dist_val)\n",
    "\n",
    "            for s_c_name, s_c_val in scaling_classes.items() :\n",
    "#                 print(s_c_name, \" : \", s_c_val)\n",
    "#             scale x_train & x_val\n",
    "                s_c = s_c_val()\n",
    "#                 print(name, \" : x_train : \", x_train)\n",
    "                scale_x_t = s_c(x_train)\n",
    "#                 print(\"scale_x_t : \", scale_x_t)\n",
    "\n",
    "#                 print(\"x_val : \", x_val)\n",
    "                scale_x_v = s_c(x_val)\n",
    "#                 print(\"scale_x_v : \", scale_x_v)\n",
    "\n",
    "                for k_nums in range(1, bound, 2) :\n",
    "    #                 print(\"k : \", k)\n",
    "\n",
    "                    knn_m = KNN(k_nums, dist_val)\n",
    "    #                 print(\"knn_m : \", knn_m)\n",
    "\n",
    "                    knn_m.train(scale_x_t, y_train)\n",
    "    #                 print(\"knn.train : \",  train)\n",
    "    #                 get f1 score & store them\n",
    "    #                 p = predict\n",
    "                    p = knn_m.predict(scale_x_v)\n",
    "\n",
    "    #                 get the max f1\n",
    "                    f1 = f1_score(y_val, p)\n",
    "\n",
    "                    if f1 > max_f1 :\n",
    "    #                     new max\n",
    "                        max_f1 = f1\n",
    "#                         print(\"max_f1 : \", max_f1)   \n",
    "\n",
    "                        self.best_k = k_nums\n",
    "#                         print(\"self.best_k : \", self.best_k)\n",
    "\n",
    "                        self.best_distance_function = name\n",
    "#                         print(\"self.best_distance_function : \", self.best_distance_function)\n",
    "\n",
    "                        self.best_model = knn_m\n",
    "#                         print(\"self.best_model : \", self.best_model)\n",
    "\n",
    "#                     print(\"k_nums = \", k_nums, \"w/ f1 of : \", f1, \"& dist_val being : \", dist_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cef949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code differs in what's being returned. We should return a list of a list (happening here) but the above \n",
    "#     returns an array of each list\n",
    "\n",
    "class NormalizationScaler:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # TODO: normalize data\n",
    "    def __call__(self, features):\n",
    "#         raise NotImplementedError\n",
    "        a = []\n",
    "        b = []\n",
    "        \n",
    "        normalized_vector = []\n",
    "        for i in range(len(features)) : \n",
    "            a = features[i][0]\n",
    "            b = features[i][1]\n",
    "#             print(\"a = \", a,  \"b = \", b)\n",
    "            \n",
    "            add_square_points = a * a + b * b\n",
    "# #             print(\"square_points : \", square_points) \n",
    "\n",
    "            square_features = np.sqrt(add_square_points)\n",
    "#             print(\"square_features : \", square_features)\n",
    "\n",
    "            if a == 0 and b == 0 :\n",
    "#                 create empty list to add points to\n",
    "                normalized_point = []\n",
    "    \n",
    "#                 add points here\n",
    "                normalized_point.append(a)\n",
    "                normalized_point.append(b)\n",
    "                \n",
    "            else : \n",
    "#                 create empty list to add points to\n",
    "                normalized_point = []\n",
    "    \n",
    "#                 normalize each point of a \n",
    "                normalized_a = a / square_features\n",
    "    \n",
    "#                 normalize each point of b\n",
    "                normalized_b = b / square_features\n",
    "            \n",
    "#                 add points here                \n",
    "                normalized_point.append(normalized_a)\n",
    "                normalized_point.append(normalized_b)\n",
    "                \n",
    "#             add points individually to the initial array\n",
    "            normalized_vector.append(normalized_point)\n",
    "                \n",
    "        return normalized_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caccfbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxScaler:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # TODO: min-max normalize data\n",
    "    def __call__(self, features):\n",
    "        store_m_m_s = []\n",
    "        \n",
    "        arr_f = np.asarray(features)\n",
    "        \n",
    "        col_1 = arr_f[:, 0]\n",
    "#         print(\"col_1 = \", col_1)\n",
    "        \n",
    "        col_2 = arr_f[:, 1] \n",
    "#         print(\"col_2 = \", col_2)\n",
    "        \n",
    "#         print(\"col_1.min = \", col_1.min())\n",
    "#         print(\"col_1.max = \", col_1.max())\n",
    "        \n",
    "#         check for col_1\n",
    "        if col_1.min() == col_1.max() :\n",
    "            arr_f[:, 0] = float(0.0)\n",
    "            store_m_m_s.append(arr_f[:, 0])\n",
    "        else :\n",
    "            c_1 = (col_1 - col_1.min()) / (col_1.max() - col_1.min())\n",
    "#             print(\"c_1 = \", c_1)\n",
    "            store_m_m_s.append(c_1)\n",
    "        \n",
    "#         check for col_2\n",
    "        if col_2.min() == col_2.max() :\n",
    "            arr_f[:, 1] = float(0.0)\n",
    "#             print(\"features = \", features)\n",
    "            store_m_m_s.append(arr_f[:, 1])\n",
    "        else :\n",
    "            c_2 = (col_2 - col_2.min()) / (col_2.max() - col_2.min())\n",
    "#             print(\"c_2 = \", c_2)\n",
    "            store_m_m_s.append(c_2)\n",
    "        \n",
    "#         print(\"store_m_m_s : \", store_m_m_s)\n",
    "        \n",
    "#         convert from array in list to list in list\n",
    "        list_a = list(store_m_m_s[0])\n",
    "        list_b = list(store_m_m_s[1])\n",
    "        \n",
    "        final_list = [list(a) for a in zip(list_a, list_b)]\n",
    "\n",
    "        return final_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae106df",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be06b851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p1 = [2.0, 2.0]\n",
    "# p2 = [2.0, 2.0]\n",
    "\n",
    "# point = [30.0, 5.8]\n",
    "\n",
    "# swap e_d w/ m_d & see what happens to the output\n",
    "dist_funcs = {\n",
    "    'euclidean_distance' : d.euclidean_distance,\n",
    "    'minkowski_distance' : d.minkowski_distance,\n",
    "    'cosine_similarity_distance' : d.cosine_similarity_distance\n",
    "}\n",
    "# print(distance_funcs)\n",
    "\n",
    "# List[List[int]] of features\n",
    "f_train = np.array([[45.2, 6.85], [211.9, 6.13], [9.34, 32.23], [82.7, 6.3], [57.8, 3.11], [2.3, 93.0]], dtype=float)\n",
    "# print(\"x_train : \", x_train)\n",
    "\n",
    "#  List[int] of labels\n",
    "l_train = np.array([0, 1, 1, 0, 0, 1])\n",
    "# print(\"y_train : \", y_train)\n",
    "\n",
    "# List[List[int]] validation data - point\n",
    "p_val = np.array([[45.0, 6.85], [211.0, 6.13], [9.34, 32.23], [82.7, 6.3], [57.8, 3.11], [2.0, 93.0]], dtype=float)\n",
    "# print(\"x_val : \", x_val)\n",
    "\n",
    "# List[int] validation labels\n",
    "l_val = np.array([0, 1, 0, 0, 1, 0])\n",
    "# print(\"y_val : \", y_val)\n",
    "\n",
    "# only for f2\n",
    "# dictionary of scalers (key is the scaler name, value is the scaler class) you need to try to normalize your data\n",
    "scaling_classes = {\n",
    "    'min_max_scale': MinMaxScaler,\n",
    "    'normalize': NormalizationScaler,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcdc508",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpt = HyperparameterTuner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed21860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: find parameters with the best f1 score on validation dataset\n",
    "hpt.tuning_without_scaling(dist_funcs, f_train, l_train, p_val, l_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a603972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find parameters with the best f1 score on validation dataset, with normalized data\n",
    "hpt.tuning_with_scaling(dist_funcs, scaling_classes, f_train, l_train, p_val, l_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6116a233",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24231795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
