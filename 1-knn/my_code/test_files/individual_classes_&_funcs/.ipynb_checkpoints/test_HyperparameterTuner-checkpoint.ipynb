{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dadaf18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false_negative :  2\n",
      "[1.0, 3.0]\n",
      "<ipynb.fs.full.test_knn.KNN object at 0x7fa1a0137d60>\n",
      "None\n",
      "squ_root_of_sum :  5.385164807134504\n",
      "squ_root_of_sum :  8.475848040166836\n",
      "squ_root_of_sum :  9.368030742904295\n",
      "squ_root_of_sum :  10.2\n",
      "squ_root_of_sum :  15.16047492659778\n",
      "squ_root_of_sum :  8.475848040166836\n",
      "squ_root_of_sum :  25.287150887357793\n",
      "squ_root_of_sum :  22.20360331117452\n",
      "squ_root_of_sum :  21.242410409367388\n",
      "squ_root_of_sum :  21.02379604162864\n",
      "squ_root_of_sum :  15.42595215861893\n",
      "squ_root_of_sum :  22.20360331117452\n",
      "squ_root_of_sum :  24.16278129686233\n",
      "squ_root_of_sum :  21.095023109728988\n",
      "squ_root_of_sum :  20.120636172845032\n",
      "squ_root_of_sum :  20.0\n",
      "squ_root_of_sum :  14.23938200906205\n",
      "squ_root_of_sum :  21.095023109728988\n",
      "squ_root_of_sum :  23.07032726252491\n",
      "squ_root_of_sum :  20.024984394500787\n",
      "squ_root_of_sum :  19.037857022259622\n",
      "squ_root_of_sum :  19.026297590440446\n",
      "squ_root_of_sum :  13.098091464026353\n",
      "squ_root_of_sum :  20.024984394500787\n",
      "squ_root_of_sum :  22.01454064930722\n",
      "squ_root_of_sum :  19.0\n",
      "squ_root_of_sum :  18.001111076819676\n",
      "squ_root_of_sum :  18.110770276274835\n",
      "squ_root_of_sum :  12.014990636700473\n",
      "squ_root_of_sum :  19.0\n",
      "squ_root_of_sum :  21.00095235935742\n",
      "squ_root_of_sum :  18.027756377319946\n",
      "squ_root_of_sum :  17.018813119603845\n",
      "squ_root_of_sum :  17.26267650163207\n",
      "squ_root_of_sum :  11.00727032465361\n",
      "squ_root_of_sum :  18.027756377319946\n",
      "squ_root_of_sum :  20.035967658189108\n",
      "squ_root_of_sum :  17.11724276862369\n",
      "squ_root_of_sum :  16.100931650062986\n",
      "squ_root_of_sum :  16.492422502470642\n",
      "squ_root_of_sum :  10.09752444909147\n",
      "squ_root_of_sum :  17.11724276862369\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# read this https://github.com/ipython/ipynb for importing notebooks\n",
    "from ipynb.fs.full.test_utils import f1_score, minkowski_distance, euclidean_distance, cosine_similarity_distance\n",
    "from ipynb.fs.full.test_knn import KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c659f",
   "metadata": {},
   "source": [
    "### tuning_without_scaling\n",
    "\n",
    "        In this part, you need to try different distance functions you implemented in part 1.1 and different values of k (among 1, 3, 5, ... , 29), and find the best model with the highest f1-score on the given validation set.\n",
    "            ==> validation set : what to test funcs & k on \n",
    "            ==> try all 3 dist funcs\n",
    "            ==> k values : odd #s from 1 - 30 step 2; call function to get k values (knn.py file) here, write a func to look inside of my knn.py & call the func w/ k values\n",
    "            ==> model w/ highest f1 score : from this class, call my f1_score func\n",
    "\n",
    "        :param distance_funcs: dictionary of distance functions (key is the function name, value is the function) you need to try to calculate the distance. Make sure you loop over all distance functions for each k value.\n",
    "            ==> for k in len(self.k), \n",
    "            ==> :param dist_funcs : {'key' : value, 'key' : value, 'key' : value}\n",
    "                ==> dist_funcs = {\n",
    "                    'minkowski_distance' : minkowski_distance(point1, point2), \n",
    "                    'euclidean_distance' : euclidean_distance(point1, point2),\n",
    "                    'cosine_similarity_distance' : cosine_similarity_distance(point1, point2)\n",
    "                    }\n",
    "                ==> which dist_func returns the smallest value for this k\n",
    "            ==> return best dist_func\n",
    "            ==> starting at 1, loop through k up to 29 & get the best dist_func for each k along the w/ the best k & best f1_score\n",
    "            ==> once we get this, it will be our best model\n",
    "            \n",
    "        :param x_train: List[List[int]] training data set to train your KNN model\n",
    "            ==> features to train\n",
    "        :param y_train: List[int] training labels to train your KNN model\n",
    "            ==> labels to train [list of 0s or 1s]\n",
    "        :param x_val:  List[List[int]] validation data\n",
    "            ==> features for validation set to find f1 score & best model\n",
    "        :param y_val: List[int] validation labels\n",
    "            ==> labels for validation set to find f1 score & best model\n",
    "        \n",
    "\n",
    "        Find the best k, distance_function (its name), and model (an instance of KNN) and assign them to self.best_k,\n",
    "        self.best_distance_function, and self.best_model respectively.\n",
    "            ==> self.best_k = best k value\n",
    "            ==> self.best_distance_function = 1 of the 3 dist funcs\n",
    "            ==> self.best_model = small knn is the object of the capital KNN class [see testKNN] so return the best model by calling the KKN class\n",
    "                store max f1 score\n",
    "\n",
    "        NOTE: self.best_scaler will be None.\n",
    "\n",
    "        NOTE: When there is a tie, choose the model based on the following priorities:\n",
    "        First check the distance function:  euclidean > Minkowski > cosine_dist\n",
    "\t\t(this will also be the insertion order in \"distance_funcs\", to make things easier).\n",
    "        For the same distance function, further break tie by prioritizing a smaller k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ce08e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperparameterTuner:\n",
    "    def __init__(self):\n",
    "        self.best_k = None # inner\n",
    "        self.best_distance_function = None # outer\n",
    "        self.best_scaler = None\n",
    "        self.best_model = None # pass d_f here; \n",
    "\n",
    "    # TODO: find parameters with the best f1 score on validation dataset\n",
    "    def tuning_without_scaling(self, distance_funcs, x_train, y_train, x_val, y_val):\n",
    "\n",
    "        max_f1 = -1\n",
    "#         if there are less than 30 points, can't have 30 neighbors\n",
    "        bound = min(30, len(x_train))\n",
    "        for name, dist_val in distance_funcs.items() :\n",
    "#             print(name, \" : \", dist_val)\n",
    "        \n",
    "            for k_nums in range(1, bound, 2) :\n",
    "#                 print(\"k : \", k)\n",
    "\n",
    "                knn_m = KNN(k_nums, dist_val)\n",
    "#                 print(\"knn : \", knn)\n",
    "\n",
    "                knn_m.train(x_train, y_train)\n",
    "#                 print(\"knn.train : \",  train)\n",
    "#                 get f1 score & store them\n",
    "#                 p = predict\n",
    "                p = knn_m.predict(x_val)\n",
    "                \n",
    "#                 get the max f1\n",
    "                f1 = f1_score(y_val, p)\n",
    "\n",
    "                if f1 > max_f1 :\n",
    "#                     new max\n",
    "                    max_f1 = f1\n",
    "                    self.best_k = k_nums \n",
    "                    self.best_distance_function = name\n",
    "                    self.best_model = knn_m\n",
    "\n",
    "    # TODO: find parameters with the best f1 score on validation dataset, with normalized data\n",
    "    def tuning_with_scaling(self, distance_funcs, scaling_classes, x_train, y_train, x_val, y_val):\n",
    "        \"\"\"\n",
    "        This part is the same as \"tuning_without_scaling\", except that you also need to try two different scalers implemented in Part 1.3. More specifically, before passing the training and validation data to KNN model, apply the scalers in scaling_classes to both of them.\n",
    "\n",
    "        :param distance_funcs: dictionary of distance functions (key is the function name, value is the function) you need to try to calculate the distance. Make sure you loop over all distance functions for each k value.\n",
    "        :param scaling_classes: dictionary of scalers (key is the scaler name, value is the scaler class) you need to try to normalize your data\n",
    "        :param x_train: List[List[int]] training data set to train your KNN model\n",
    "        :param y_train: List[int] train labels to train your KNN model\n",
    "        :param x_val: List[List[int]] validation data\n",
    "        :param y_val: List[int] validation labels\n",
    "\n",
    "        Find the best k, distance_function (its name), scaler (its name), and model (an instance of KNN), and assign them to self.best_k, self.best_distance_function, best_scaler, and self.best_model respectively.\n",
    "\n",
    "        NOTE: When there is a tie, choose the model based on the following priorities:\n",
    "        First check scaler, prioritizing \"min_max_scale\" over \"normalize\" (which will also be the insertion order of scaling_classes). Then follow the same rule as in \"tuning_without_scaling\".\n",
    "        \"\"\"\n",
    "\n",
    "        # You need to assign the final values to these variables\n",
    "        self.best_k = None\n",
    "        self.best_distance_function = None\n",
    "        self.best_scaler = None\n",
    "        self.best_model = None\n",
    "#         raise NotImplementedError\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2215f9",
   "metadata": {},
   "source": [
    "# Class\n",
    "1. HyperparameterTuner\n",
    "\n",
    "## Functions\n",
    "\n",
    "1. tuning_without_scaling w/ params :\n",
    "    - distance_funcs\n",
    "    - x_train\n",
    "    - y_train\n",
    "    - x_val\n",
    "    - y_val\n",
    "2. tuning_with_scaling w/ params :\n",
    "    - distance_funcs\n",
    "    - scaling_classes\n",
    "    - x_train\n",
    "    - y_train\n",
    "    - x_val\n",
    "    - y_val\n",
    "    \n",
    "### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2126aee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "# p1 = [2.0, 2.0]\n",
    "# p2 = [2.0, 2.0]\n",
    "\n",
    "p1 = [1.0, 2.0]\n",
    "p2 = [2.0, 1.0]\n",
    "point = [30.0, 5.8]\n",
    "\n",
    "dist_funcs = {\n",
    "    'minkowski_distance' : minkowski_distance(p1, p2),\n",
    "    'euclidean_distance' : euclidean_distance(p1, p2),\n",
    "    'cosine_similarity_distance' : cosine_similarity_distance(p1, p2)\n",
    "}\n",
    "# print(distance_funcs)\n",
    "\n",
    "# List[List[int]] of features\n",
    "f_train = np.array([[45.2, 6.85], [211.9, 6.13], [9.34, 32.23], [82.7, 6.3], [57.8, 3.11], [2.3, 93.0]], dtype=float)\n",
    "# print(\"f_train : \", f_train)\n",
    "\n",
    "#  List[int] of labels\n",
    "l_train = np.array([0, 1, 0, 0, 1, 1])\n",
    "# print(\"y_train : \", y_train)\n",
    "\n",
    "# List[List[int]] validation data\n",
    "f_val = np.array([[45.0, 6.85], [211.0, 6.13], [9.34, 32.23], [82.7, 6.3], [57.8, 3.11], [2.0, 93.0]], dtype=float)\n",
    "# print(\"x_val : \", x_val)\n",
    "\n",
    "# List[int] validation labels\n",
    "l_val = np.array([0, 1, 0, 0, 1, 1])\n",
    "# print(\"y_val : \", y_val)\n",
    "\n",
    "# only for f2\n",
    "# dictionary of scalers (key is the scaler name, value is the scaler class) you need to try to normalize your data\n",
    "# scaling_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f25d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpt = HyperparameterTuner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3586bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minkowski_distance  :  1.2599210498948732\n",
      "k :  1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fz/zn5r8vq12nv5p23dtlr15sk40000gn/T/ipykernel_58394/1069223365.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO: find parameters with the best f1 score on validation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuning_without_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_funcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/fz/zn5r8vq12nv5p23dtlr15sk40000gn/T/ipykernel_58394/2024247721.py\u001b[0m in \u001b[0;36mtuning_without_scaling\u001b[0;34m(self, distance_funcs, x_train, y_train, x_val, y_val)\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mget_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#                 print(\" get_train : \",  get_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mget_k_nei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_k_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m#                 print(\"get_k_nei : \",  get_k_nei)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#                 get_p = knn.predict(self, features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/development/csci_567_machine_learning/1/startercode.0/test_knn.ipynb\u001b[0m in \u001b[0;36mget_k_neighbors\u001b[0;34m(self, point)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;34m\"            Sort indices of distances by smallest --> largest in list [1, 4, 2, 0, 3]\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m\"            k is how far to search in sorted indicis list\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;34m\"                k = 1, return [1]\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;34m\"                k = 3, return [1, 4, 2]\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;34m\"                k = 5, return [1, 4, 2, 0, 3]\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "# TODO: find parameters with the best f1 score on validation dataset\n",
    "hpt.tuning_without_scaling(dist_funcs, f_train, l_train, f_val, l_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ef446eac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaling_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fz/zn5r8vq12nv5p23dtlr15sk40000gn/T/ipykernel_57224/3598522445.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO: find parameters with the best f1 score on validation dataset, with normalized data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuning_with_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_funcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaling_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'scaling_classes' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: find parameters with the best f1 score on validation dataset, with normalized data\n",
    "hpt.tuning_with_scaling(dist_funcs, scaling_classes, f_train, l_train, f_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe71e21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
